{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from typing import Text, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train.csv'\n",
    "\n",
    "df = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7766</td>\n",
       "      <td>Wonderful summary of Sai's words on nature. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4631</td>\n",
       "      <td>I'm not going to lie, I have a tough time liki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67707</td>\n",
       "      <td>This is an excellent book.  It has allowed me ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93531</td>\n",
       "      <td>Reading the series one book at a time; fell in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58527</td>\n",
       "      <td>Oh my gosh! So amazing! I love this book so mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                               TEXT  LABEL\n",
       "0   7766  Wonderful summary of Sai's words on nature. It...      0\n",
       "1   4631  I'm not going to lie, I have a tough time liki...      0\n",
       "2  67707  This is an excellent book.  It has allowed me ...      0\n",
       "3  93531  Reading the series one book at a time; fell in...      0\n",
       "4  58527  Oh my gosh! So amazing! I love this book so mu...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 70187 \n",
      "\n",
      "Empty values in column ID: 0\n",
      "Empty values in column TEXT: 7\n",
      "Empty values in column LABEL: 0 \n",
      "\n",
      "Number of Irrelevant Reviews 35000\n",
      "Number of Positive Reviews 17645\n",
      "Number of Negative Reviews 17542 \n",
      "\n",
      "Avg Length of Irrelevant Reviews 426.21105714285716\n",
      "Avg Length of Positive Reviews 1332.3479739302918\n",
      "Avg Length of Positive Reviews 1298.990822027135\n"
     ]
    }
   ],
   "source": [
    "print(\"Total rows:\", df.shape[0],'\\n')\n",
    "\n",
    "print(\"Empty values in column ID:\",df['ID'].isna().sum())\n",
    "print(\"Empty values in column TEXT:\",df['TEXT'].isna().sum())\n",
    "print(\"Empty values in column LABEL:\",df['LABEL'].isna().sum(),'\\n')\n",
    "\n",
    "irrelevant_slice = df['TEXT'].loc[df['LABEL']==0]\n",
    "pos_slice = df['TEXT'].loc[df['LABEL']==1]\n",
    "neg_slice = df['TEXT'].loc[df['LABEL']==2]\n",
    "\n",
    "print(\"Number of Irrelevant Reviews\", len(irrelevant_slice))\n",
    "print(\"Number of Positive Reviews\", len(pos_slice))\n",
    "print(\"Number of Negative Reviews\", len(neg_slice),'\\n')\n",
    "\n",
    "print(\"Avg Length of Irrelevant Reviews\", sum([len(text) for text in irrelevant_slice.dropna()]) / len(irrelevant_slice))\n",
    "print(\"Avg Length of Positive Reviews\", sum([len(text) for text in pos_slice.dropna()]) / len(pos_slice))\n",
    "print(\"Avg Length of Positive Reviews\", sum([len(text) for text in neg_slice.dropna()]) / len(neg_slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\"EMPTY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I opt for a 85-15 split betwen train and development sets\n",
    "train_df, dev_df = train_test_split(df,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(sublinear_tf=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer = TfidfVectorizer(ngram_range=(1,1),use_idf=True,sublinear_tf=True)\n",
    "featurizer.fit(train_df['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102381"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featurizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self) -> None:\n",
    "        self.lr_model = LogisticRegression(max_iter=500)\n",
    "        self.nb_model = MultinomialNB()\n",
    "        self.svm_model = LinearSVC(max_iter=2500)\n",
    "    def fit(self, features, labels):\n",
    "        self.lr_model.fit(features,labels)\n",
    "        self.nb_model.fit(features,labels)\n",
    "        self.svm_model.fit(features,labels)\n",
    "\n",
    "    def predict(self, features):\n",
    "        return self.lr_model.predict(features),self.nb_model.predict(features),self.svm_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = featurizer.transform(train_df['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59658, 102381)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<59658x102381 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5546185 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "\n",
    "clf.fit(features,train_df['LABEL'])\n",
    "\n",
    "lr_preds,nb_preds,svm_preds = clf.predict(featurizer.transform(dev_df['TEXT']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_printout(modelname:str, labels, preds):\n",
    "\n",
    "    print(modelname,\": -------------------\")\n",
    "\n",
    "    print(classification_report(labels,preds,target_names=['Not Movie','Positive','Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression : -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Movie       0.98      0.99      0.98      5247\n",
      "    Positive       0.88      0.87      0.88      2710\n",
      "    Negative       0.89      0.88      0.89      2572\n",
      "\n",
      "    accuracy                           0.93     10529\n",
      "   macro avg       0.92      0.91      0.92     10529\n",
      "weighted avg       0.93      0.93      0.93     10529\n",
      "\n",
      "Multinomal NB : -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Movie       0.96      0.98      0.97      5247\n",
      "    Positive       0.86      0.78      0.82      2710\n",
      "    Negative       0.83      0.88      0.85      2572\n",
      "\n",
      "    accuracy                           0.90     10529\n",
      "   macro avg       0.88      0.88      0.88     10529\n",
      "weighted avg       0.90      0.90      0.90     10529\n",
      "\n",
      "Linear Support Vector Machine : -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Movie       0.98      0.99      0.99      5247\n",
      "    Positive       0.88      0.88      0.88      2710\n",
      "    Negative       0.89      0.88      0.89      2572\n",
      "\n",
      "    accuracy                           0.93     10529\n",
      "   macro avg       0.92      0.92      0.92     10529\n",
      "weighted avg       0.93      0.93      0.93     10529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_printout(\"Linear Regression\", dev_df['LABEL'],lr_preds)\n",
    "metric_printout(\"Multinomal NB\", dev_df['LABEL'],nb_preds)\n",
    "metric_printout(\"Linear Support Vector Machine\", dev_df['LABEL'],svm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'data/test.csv'\n",
    "\n",
    "test_df = pd.read_csv(test_path)\n",
    "test_df = test_df.fillna(\"EMPTY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,predictions = clf.predict(featurizer.transform(test_df['TEXT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30073</th>\n",
       "      <td>86744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30074</th>\n",
       "      <td>27493</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30075</th>\n",
       "      <td>72221</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30076</th>\n",
       "      <td>16355</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30077</th>\n",
       "      <td>83963</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30078 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Predicted\n",
       "0      18742          0\n",
       "1      14108          0\n",
       "2      52871          0\n",
       "3      39785          0\n",
       "4      46174          0\n",
       "...      ...        ...\n",
       "30073  86744          2\n",
       "30074  27493          2\n",
       "30075  72221          2\n",
       "30076  16355          2\n",
       "30077  83963          2\n",
       "\n",
       "[30078 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(columns=['ID','Predicted'])\n",
    "submission['ID'] = test_df['ID']\n",
    "submission['Predicted'] = predictions\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission csv\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
